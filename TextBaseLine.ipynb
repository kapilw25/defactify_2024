{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import requests\n",
        "import json\n",
        "together_apikey=userdata.get('togetherapi')\n",
        "firework_apikey=userdata.get('fireapi')"
      ],
      "metadata": {
        "id": "5-WSqsHeAhqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqIDAzzEAFa9"
      },
      "outputs": [],
      "source": [
        "def togetherai(question,model,api_key=together_apikey):\n",
        "    # url = \"https://api.fireworks.ai/inference/v1/chat/completions\" #for FW\n",
        "    url = \"https://api.together.xyz/v1/chat/completions\"  #-- for Together AI\n",
        "    formatted_prompt = f\"Regenerate provided text: TEXT = {question}\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        \"max_tokens\": 1024,\n",
        "        \"top_p\": 1,\n",
        "        \"top_k\": 40,\n",
        "        \"presence_penalty\": 0,\n",
        "        \"frequency_penalty\": 0,\n",
        "        \"temperature\": 0.5,\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Accept\": \"application/json\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Extract the output message\n",
        "        output_message = response.json()['choices'][0]['message']['content']\n",
        "        return output_message\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fireworks(question,api_key=firework_apikey,model=\"accounts/yi-01-ai/models/yi-large\"):\n",
        "    url = \"https://api.fireworks.ai/inference/v1/chat/completions\" #for FW\n",
        "    # url = \"https://api.together.xyz/v1/chat/completions\"  #-- for Together AI\n",
        "    formatted_prompt = f\"Regenerate the text: TEXT={question}\\n\"\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "        \"max_tokens\": 1024,\n",
        "        \"top_p\": 1,\n",
        "        \"top_k\": 40,\n",
        "        \"presence_penalty\": 0,\n",
        "        \"frequency_penalty\": 0,\n",
        "        \"temperature\": 0.5,\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Accept\": \"application/json\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Extract the output message\n",
        "        output_message = response.json()['choices'][0]['message']['content']\n",
        "        return output_message\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "z2ndSpFTE40a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "together_ai_models=[\"Qwen/Qwen2-72B-Instruct\",\"google/gemma-2-9b-it\",\"mistralai/Mistral-7B-Instruct-v0.1\",\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "7YDHc75pBeos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Score:\n",
        "    def __init__(self,edit_score,new_text,model):\n",
        "        self.edit_score=edit_score\n",
        "        self.new_text=new_text\n",
        "        self.model=model\n"
      ],
      "metadata": {
        "id": "tjtpM5kXu9NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUEl99Bixx1E",
        "outputId": "cdd1da0c-b0b0-4aa9-cc08-fcaa2da5afed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import Levenshtein\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "def get_edit_distance(text1, text2):\n",
        "    tokens1 = word_tokenize(text1)\n",
        "    tokens2 = word_tokenize(text2)\n",
        "    joined1 = \" \".join(tokens1)\n",
        "    joined2 = \" \".join(tokens2)\n",
        "    distance = Levenshtein.distance(joined1, joined2)\n",
        "    return distance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sXKPblJvxEY",
        "outputId": "dcb28953-c28d-405d-f023-a3e6ea07185f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_text(text):\n",
        "    edit_distance_score=[]\n",
        "    for model in together_ai_models:\n",
        "        new_text=togetherai(text,model)\n",
        "        edit_score=get_edit_distance(text,new_text)\n",
        "        edit_distance_score.append(Score(edit_score,new_text,model))\n",
        "    new_text=fireworks(text)\n",
        "    edit_score=get_edit_distance(text,new_text)\n",
        "    edit_distance_score.append(Score(edit_score,new_text,\"Yi-Large\"))\n",
        "    return edit_distance_score"
      ],
      "metadata": {
        "id": "UIWTBCEQs7nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"\n",
        "Global Economy Global Economy Supported by World Bank Sees Rosier Growth Outlook But rising trade barriers pose a long-term threat to global output as protectionist policies spread, the bank said. ByAlan Rappeport Reporting from Washington The World Bank on Tuesday raised its outlook for the world economy this year but warned that the rise of new trade barriers and protectionist policies posed a long-term threat to global growth. In its latest Global Economic Prospects report, the World Bank projected global growth to hold steady at 2.6 percent this year, an upgrade from itsJanuary forecastof 2.4 percent, and predicted that output would edge higher to 2.7 percent in 2025. The forecasts showed the global economy stabilizing after being rocked in recent years by the pandemic and the wars in Ukraine and the Middle East. “Four years after the upheavals caused by the pandemic, conflicts, inflation and monetary tightening, it appears that global economic growth is steadying,” Indermit Gill, the World Bank’s chief economist, said in a statement accompanying the report. However, sluggish growth continues to haunt the world’s poorest economies, which are still grappling with inflation and the burdens of high debt. The bank noted that over the next three years, countries that account for more than 80 percent of the world’s population would experience slower growth than in the decade before the pandemic. The slightly brighter forecast was led by the resilience of the U.S. economy, which continues to defy expectations despite higher interest rates. Overall, advanced economies are growing at an annual rate of 1.5 percent, with output remaining sluggish in Europe and Japan. By contrast, emerging market and developing economies are growing at a rate of 4 percent, led by China and Indonesia. Although growth is expected to be a bit stronger than previously forecast, the World Bank said prices were easing more slowly than it projected six months ago. It foresees global inflation moderating to 3.5 percent in 2024 and 2.9 percent next year. That gradual decline is likely to lead central banks to delay interest rate cuts, dimming prospects for growth in developing economies.\"\"\""
      ],
      "metadata": {
        "id": "HiaWymNVx_oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=detect_text(text)"
      ],
      "metadata": {
        "id": "J31sgOBlthXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in data:\n",
        "    print(f\"{item.model} -- {item.edit_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIhvLew4zRDR",
        "outputId": "0a6e4fb8-2de5-4e01-be9d-5ad3fd28c9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen/Qwen2-72B-Instruct -- 1047\n",
            "google/gemma-2-9b-it -- 1640\n",
            "mistralai/Mistral-7B-Instruct-v0.1 -- 834\n",
            "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo -- 165\n",
            "Yi-Large -- 1221\n"
          ]
        }
      ]
    }
  ]
}